{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMA5MCZqVSKs"
      },
      "source": [
        "# Denoising autoencoder\n",
        "\n",
        "We are going to use ```keras``` (```tensorflow``` as backend) to build a simple denoising autoencoder.\n",
        "\n",
        "## Libraries\n",
        "We'll be using Pillow a fork of PIL, the Python Image Library, Tensorflow, Numpy and Matplotlib.\n",
        "You can install Pillow with \n",
        "```\n",
        "!pip install Pillow\n",
        "```\n",
        "\n",
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "O8iGXeEzVSK3"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Activation, Dense, Input\n",
        "from tensorflow.keras.layers import Conv2D, Flatten\n",
        "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js-C2r4yVSK6"
      },
      "source": [
        "## Data\n",
        "\n",
        "### Load and check the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KmTPFsp7VSK7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# load the data\n",
        "(x_train, _), (x_test, _) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_train, y_train, X_test, y_test\n",
        "\n",
        "# we do not care about the y-labels, we are not taking out the \"_\"\n",
        "# unsupervised learning - we don't need labels\n",
        "# so "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape\n",
        "\n",
        "# 60000 by 28 by 28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train[0].shape\n",
        "\n",
        "# Encoded by un-signed integer, 28\n",
        "# if you'd like to plot it\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'img' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mimg\u001b[49m\u001b[38;5;241m.\u001b[39mshow(x_train[\u001b[38;5;241m0\u001b[39m])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
          ]
        }
      ],
      "source": [
        "img.show(x_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2Rlq6JyVSLB"
      },
      "source": [
        "#### Take a look at the data\n",
        "\n",
        "Just look at one or two examples to get an idea of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AsRwg5FVSLD"
      },
      "source": [
        "### Reshape the images\n",
        "\n",
        "When loaded, each image is 2-dimensional, 28 x 28 pixels. But, due to how keras and tensorflow handles images we want the images to have the shape 28 x 28 x num_channels, where num_channels is the number of color channels in the images. These are grey scale images so the num_channels is 1, but in colour images num_channels is 3 (RGB)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr6-AUzvVSLE"
      },
      "source": [
        "### Normalize the input data\n",
        "Check the range of values and data type (```dtype```) or the input data.\n",
        "\n",
        "Is this ok, or should we normalize the data?\n",
        "\n",
        "What about the data type?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc6Zk362VSLI"
      },
      "source": [
        "### Generate corrupted MNIST images\n",
        "\n",
        "Add noise with normal distribution centered at 0.5 and std=0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "RfibP7FuVSLJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlQIYEr1VSLK"
      },
      "source": [
        "### Check the corrupted images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHAASvDIVSLM"
      },
      "source": [
        "## Model\n",
        "\n",
        "### Build the model\n",
        "Use ```Sequential()``` and add two encoder layers, one hidden/middle layer, and two decoder layers.\n",
        "For the layers, use ```Dense()```, i.e. densly connected layers (not convolutional or dropout)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVOi8yuCVSLN"
      },
      "outputs": [],
      "source": [
        "# Network parameters\n",
        "input_shape = x_train.shape[1:]\n",
        "batch_size = 128\n",
        "kernel_size = 3\n",
        "latent_dim = 16\n",
        "# Encoder/Decoder number of CNN layers and filters per layer (depth)\n",
        "layer_filters = [32, 64]\n",
        "\n",
        "# Build the Autoencoder Model\n",
        "# First build the Encoder Model\n",
        "inputs = Input(shape=input_shape, name='encoder_input')\n",
        "x = inputs\n",
        "# Stack of Conv2D blocks\n",
        "# Notes:\n",
        "# 1) Use Batch Normalization before ReLU on deep networks\n",
        "# 2) Use MaxPooling2D as alternative to strides>1\n",
        "# - faster but not as good as strides>1\n",
        "for filters in layer_filters:\n",
        "    x = Conv2D(filters=filters,\n",
        "               kernel_size=kernel_size,\n",
        "               strides=2,\n",
        "               activation='relu',\n",
        "               padding='same')(x)\n",
        "\n",
        "# Shape info needed to build Decoder Model\n",
        "shape = K.int_shape(x)\n",
        "\n",
        "# Generate the latent vector\n",
        "x = Flatten()(x)\n",
        "latent = Dense(latent_dim, name='latent_vector')(x)\n",
        "\n",
        "# Instantiate Encoder Model\n",
        "encoder = Model(inputs, latent, name='encoder')\n",
        "encoder.summary()\n",
        "\n",
        "# Build the Decoder Model\n",
        "latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
        "x = Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\n",
        "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
        "\n",
        "# Stack of Transposed Conv2D blocks\n",
        "# Notes:\n",
        "# 1) Use Batch Normalization before ReLU on deep networks\n",
        "# 2) Use UpSampling2D as alternative to strides>1\n",
        "# - faster but not as good as strides>1\n",
        "for filters in layer_filters[::-1]:\n",
        "    x = Conv2DTranspose(filters=filters,\n",
        "                        kernel_size=kernel_size,\n",
        "                        strides=2,\n",
        "                        activation='relu',\n",
        "                        padding='same')(x)\n",
        "\n",
        "x = Conv2DTranspose(filters=1,\n",
        "                    kernel_size=kernel_size,\n",
        "                    padding='same')(x)\n",
        "\n",
        "outputs = Activation('sigmoid', name='decoder_output')(x)\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBp1ybXUVSLO"
      },
      "outputs": [],
      "source": [
        "# Instantiate Decoder Model\n",
        "decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "decoder.summary()\n",
        "\n",
        "# Autoencoder = Encoder + Decoder\n",
        "# Instantiate Autoencoder Model\n",
        "autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfjVg1XUVSLP"
      },
      "source": [
        "### Compile and train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "cQ6nqk8SVSLP"
      },
      "outputs": [],
      "source": [
        "autoencoder.compile(loss='mse', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeT3M96tVSLP"
      },
      "outputs": [],
      "source": [
        "# Train the autoencoder\n",
        "autoencoder.fit(x_train_noisy,\n",
        "                x_train,\n",
        "                validation_data=(x_test_noisy, x_test),\n",
        "                epochs=30,\n",
        "                batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRT4qmi-VSLQ"
      },
      "source": [
        "## Test\n",
        "\n",
        "### Test our brand new denoiser\n",
        "\n",
        "Pro-tip: use ```model.predict()```\n",
        "\n",
        "and take a look at the result (try plotting the original and reconstructed images next to each other)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o7Yn1rxVSLQ"
      },
      "source": [
        "**Are we doing denoising?**\n",
        "\n",
        "Add some noise to a test image and try to reconstruct it.\n",
        "Pro-tip:\n",
        "    Use ```np.random.something```\n",
        "    \n",
        "Plot the original, noise added and reconstructed images side-by-side"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRAinyrFVSLS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MBAN6500A_class08_Autoencoder.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
